apiVersion: v1
kind: Namespace
metadata:
  labels:
    app: kube-failover-controller
  name: kubevirt-system
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  labels:
    app: kube-failover-controller
  name: virtnodefailcontroller
  namespace: kubevirt-system
spec:
  privileged: true
  allowPrivilegeEscalation: true
  allowedCapabilities:
    - "*"
  #  - NET_ADMIN
  #  - NET_RAW
  #  - SYS_ADMIN
  fsGroup:
    rule: RunAsAny
  hostNetwork: true
  runAsUser:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  volumes:
    - "*"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: kube-failover-controller
  name: virtnodefailcontroller
  namespace: kubevirt-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kube-failover-controller
  name: kubevirt-system:controller:virt-node-fail-controller
rules:
  - apiGroups:
      - ""
    resources:
      - pods/log
      - pods
      - services
      - endpoints
      - events
      - nodes
    verbs:
      - get
      - update
      - create
      - delete
      - list
      - watch
      - patch
  - apiGroups:
      - "kubevirt.io"
    resources:
      - virtualmachineinstances
    verbs:
      - get
      - update
      - create
      - delete
      - list
      - watch
      - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app: kube-failover-controller
  name: config-watcher
  namespace: kubevirt-system
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - events
    verbs:
      - get
      - update
      - create
      - delete
      - list
      - watch
      - patch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: kube-failover-controller
  name: kubevirt-system:controller:virt-node-fail-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubevirt-system:controller:virt-node-fail-controller
subjects:
  - kind: ServiceAccount
    name: virtnodefailcontroller
    namespace: kubevirt-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app: kube-failover-controller
  name: config-watcher
  namespace: kubevirt-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: config-watcher
subjects:
  - kind: ServiceAccount
    name: virtnodefailcontroller
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: kube-failover-controller
    component: virtnodefailcontroller
  name: kube-failover-controller
  namespace: kubevirt-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kube-failover-controller
      component: virtnodefailcontroller
  template:
    metadata:
      labels:
        app: kube-failover-controller
        component: virtnodefailcontroller
    spec:
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      affinity:
        nodeAffinity: # it needs for calicoctl command using /.kube/config
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: node-role.kubernetes.io/master
                    operator: Exists
                    values:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - kube-failover-controller
            topologyKey: kubernetes.io/hostname
      containers:
        - name: kube-failover-controller
          image: tmaxcloudck/kube-failover-controller:%FAILOVER_VERSION%
          env:
          - name: CALICO_DATASTORE_TYPE
            value: kubernetes
          - name: CALICO_KUBECONFIG
            value: %HOME%/.kube/config
          resources:
            requests:
              memory: "300Mi"
              cpu: "500m"
            limits:
              memory: "1000Mi"
              cpu: "1"
          volumeMounts:
          - mountPath: %HOME%/.kube
            name: kube-config
          securityContext:
            privileged: true
      volumes:
      - name: kube-config
        hostPath:
          path: %HOME%/.kube
          type: Directory
      serviceAccountName: virtnodefailcontroller
      hostNetwork: true
